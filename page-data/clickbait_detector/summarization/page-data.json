{"componentChunkName":"component---src-templates-docs-js","path":"/clickbait_detector/summarization","result":{"data":{"mdx":{"body":"var _excluded = [\"components\"];\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Summarization Module\",\n  \"description\": \"Summarize news content\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"\\uB09A\\uC2DC\\uC131 \\uC81C\\uBAA9\\uC740 \\uAC00\\uC9C4 \\uAE30\\uC0AC\\uC758 \\uB0B4\\uC6A9\\uC744 \\uD1B5\\uD574 \\uC0C8\\uB85C\\uC6B4 \\uC81C\\uBAA9\\uC744 \\uC0DD\\uC131\\uD574\\uC8FC\\uB294 \\uC694\\uC57D \\uBAA8\\uB378 \\uAC1C\\uBC1C\\uC744 \\uB2F4\\uB2F9\\uD558\\uC600\\uB2E4.\"), mdx(\"h1\", {\n    \"id\": \"base-모델-선정\"\n  }, \"Base \\uBAA8\\uB378 \\uC120\\uC815\"), mdx(\"p\", null, \"\\uB192\\uC740 \\uD55C\\uAD6D\\uC5B4 \\uC778\\uC2DD\\uC728\\uC744 \\uC704\\uD574 \\uBB38\\uC11C \\uC694\\uC57D \\uBAA8\\uB378\\uB85C \\uCC44\\uD0DD\\uB41C BART\\uC758 \\uD55C\\uAD6D\\uC5B4 \\uBB38\\uC7A5\\uC73C\\uB85C pre-trained\\uB41C \\uBAA8\\uB378\\uC744 \\uCC3E\\uC544\\uBCF4\\uC558\\uB2E4.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/SKT-AI/KoBART\"\n  }, \"SKT-AI KoBART\")), mdx(\"p\", null, \"SKT\\uC5D0\\uC11C \\uC81C\\uACF5\\uD558\\uB294 KoBART\\uAC00 \\uC788\\uC5B4 \\uD574\\uB2F9 github\\uC5D0\\uC11C \\uC81C\\uC2DC\\uD558\\uB294 dependency\\uB97C \\uC124\\uCE58\\uB97C \\uC704\\uD574 \\uC0C8\\uB85C\\uC6B4 conda \\uD658\\uACBD\\uC744 \\uCD94\\uAC00\\uD558\\uAE30 \\uC2EB\\uC5B4 \\uB2E4\\uB978 \\uBC29\\uBC95\\uC744 \\uCC3E\\uC544\\uBCF4\\uC558\\uB2E4.\\n\\uCC3E\\uC544\\uBCF4\\uB2C8 huggingface hub \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://huggingface.co/gogamza/kobart-base-v2\"\n  }, \"gogamza/kobart-base-v2\"), \"\\uB85C \\uB3D9\\uC77C\\uD55C \\uBAA8\\uB378\\uC774 \\uC774\\uBBF8 \\uC62C\\uB77C\\uC628 \\uB4EF \\uD558\\uC5EC \\uC774\\uB97C \\uC0AC\\uC6A9\\uD558\\uAE30\\uB85C \\uD588\\uB2E4. \"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"import torch\\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\\nmodel_name = 'gogamza/kobart-base-v2'\\n\\n# get model, tokenizer\\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\\ntokenizer = AutoTokenizer.from_pretrained(model_name)\\n\")), mdx(\"h1\", {\n    \"id\": \"dataset\"\n  }, \"Dataset\"), mdx(\"p\", null, \"\\uB370\\uC774\\uD130\\uC14B\\uC740 AI-Hub\\uC5D0\\uC11C \\uC81C\\uACF5\\uD558\\uB294 \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=&topMenu=&aihubDataSe=data&dataSetSn=97\"\n  }, \"\\uBB38\\uC11C\\uC694\\uC57D \\uD14D\\uC2A4\\uD2B8\"), \"\\uB97C \\uC0AC\\uC6A9\\uD558\\uAE30\\uB85C \\uD558\\uC600\\uB2E4.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"\\uC704 \\uB370\\uC774\\uD130\\uC14B\\uC740 \\uBC95\\uB960, \\uC0AC\\uC124, \\uADF8\\uB9AC\\uACE0 \\uC2E0\\uBB38\\uAE30\\uC0AC \\uCD1D \\uC138 \\uAC00\\uC9C0 \\uBC94\\uC8FC\\uB85C \\uB098\\uB258\\uC5B4 \\uC788\\uB294\\uB370, \\uC6B0\\uB9AC\\uC758 \\uAD00\\uC2EC \\uC601\\uC5ED\\uC740 \\uB274\\uC2A4\\uC758 \\uC694\\uC57D\\uC774\\uAE30 \\uB54C\\uBB38\\uC5D0 \\uB274\\uC2A4 \\uCE74\\uD14C\\uACE0\\uB9AC\\uC5D0 \\uB300\\uD55C \\uB370\\uC774\\uD130\\uB9CC \\uC0AC\\uC6A9\\uD558\\uB3C4\\uB85D \\uD55C\\uB2E4.\"), mdx(\"p\", null, \"\\uAE30\\uBCF8\\uC801\\uC73C\\uB85C \\uC81C\\uBAA9, \\uBCF8\\uBB38, \\uC694\\uC57D \\uBFD0 \\uC544\\uB2C8\\uB77C \\uBD88\\uC6A9\\uC5B4 \\uC704\\uCE58 \\uC815\\uBCF4, \\uBBF8\\uB514\\uC5B4 \\uBA85, \\uC2E0\\uB8B0\\uC131\\uACFC \\uAC19\\uC740 \\uAE30\\uC0AC\\uC758 \\uBA54\\uD0C0 \\uB370\\uC774\\uD130\\uB97C \\uD3EC\\uD568\\uD558\\uACE0 \\uC788\\uB294\\uB370 \\uC774\\uB97C \\uBAA8\\uB378 \\uD559\\uC2B5\\uC5D0 \\uC5B4\\uB5BB\\uAC8C \\uC0AC\\uC6A9\\uD560 \\uC218 \\uC788\\uC744\\uAE4C \\uBD84\\uC11D\\uD558\\uB294 \\uC2DC\\uAC04\\uC774 \\uD544\\uC694\\uD560 \\uAC83 \\uAC19\\uB2E4.\\n\\uC77C\\uB2E8 \\uAE30\\uBCF8\\uC801\\uC778 \\uC694\\uC57D \\uC791\\uC5C5 \\uD14C\\uC2A4\\uD2B8\\uB97C \\uC704\\uD574 \\uBCF8\\uBB38\\uC758 \\uB0B4\\uC6A9\\uACFC \\uC694\\uC57D\\uB41C \\uB77C\\uBCA8 \\uB370\\uC774\\uD130\\uB97C \\uC0AC\\uC6A9\\uD558\\uC5EC \\uD559\\uC2B5\\uC744 \\uC9C4\\uD589\\uD558\\uB3C4\\uB85D \\uD558\\uACA0\\uB2E4.\"), mdx(\"p\", null, \"\\uB9E4\\uBC88 \\uD559\\uC2B5\\uC744 \\uC2DC\\uC791\\uD560 \\uB54C \\uB9C8\\uB2E4 json \\uB370\\uC774\\uD130\\uB97C \\uC77D\\uACE0 \\uC5EC\\uB7EC \\uC804\\uCC98\\uB9AC \\uACFC\\uC815\\uC744 \\uAC70\\uCE58\\uB294 \\uAC83\\uC774 \\uC0DD\\uAC01\\uBCF4\\uB2E4 \\uC2DC\\uAC04\\uC774 \\uC624\\uB798 \\uAC78\\uB824 \\uCC98\\uB9AC\\uB41C \\uB370\\uC774\\uD130\\uB97C \\uC800\\uC7A5\\uD558\\uACE0 \\uD559\\uC2B5 \\uB9C8\\uB2E4 \\uBD88\\uB7EC\\uC624\\uB294 \\uAC83\\uC73C\\uB85C \\uC124\\uACC4\\uD558\\uC600\\uB2E4.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"import json\\nfrom threading import Thread\\nfrom datasets import Dataset\\n\\ncreates_dataset = True\\ndataset_file = '../data/dataset1.pt'\\ntrain_file = '../data/train_original.json' # num of total data is about 240000\\nvalid_file = '../data/valid_original.json' # num of total data is about 30000\\nnum_threads = 8\\n\\n# read json & tokenize\\ndef get_input_and_labels(documents, articles, abstractives):\\n    for document in documents:\\n        article = ''\\n        for text in document['text']:\\n            if len(text) > 0:\\n                article += (text[0]['sentence'] + ' ')\\n        articles.append(article)\\n        \\n        abstractive = document['abstractive']\\n        if len(abstractive) > 0:\\n            abstractive = abstractive[0]\\n        abstractives.append(abstractive)\\n        \\ndef get_dataset_from_json(json_file, num_data=0):\\n    with open(json_file, 'r') as f:\\n        json_data = json.load(f)\\n        documents = json_data['documents']\\n        data_size = len(documents)\\n        if num_data == 0 or num_data > data_size:\\n            num_data = data_size\\n        \\n        data_per_threads = num_data//num_threads\\n        t_results = []\\n        threads = []\\n        for i in range(num_threads-1):\\n            t_result = [[], []]\\n            t_results.append(t_result)\\n            \\n            thread = Thread(target=get_input_and_labels, args=(documents[i*data_per_threads:(i+1)*data_per_threads], t_result[0], t_result[1],))\\n            thread.daemon = True\\n            thread.start()\\n            threads.append(thread)\\n            \\n        data_dict = {'article':[], 'abstractive':[]}\\n        get_input_and_labels(documents[(num_threads-1)*data_per_threads:], data_dict['article'], data_dict['abstractive'])\\n\\n        for thread in threads:\\n            thread.join()\\n        \\n        for t_result in t_results:\\n            data_dict['article'].extend(t_result[0])\\n            data_dict['abstractive'].extend(t_result[1])\\n            \\n        return Dataset.from_dict(data_dict)\\n\\nif creates_dataset:\\n    train_dataset = get_dataset_from_json(train_file)\\n    val_dataset = get_dataset_from_json(valid_file)\\n\")), mdx(\"p\", null, \"batch \\uC791\\uC5C5\\uC744 \\uC704\\uD574 \\uBAA8\\uB4E0 input\\uC744 \\uB3D9\\uC77C\\uD55C BART \\uCD5C\\uB300 \\uAE38\\uC774\\uC778 1024\\uB85C \\uC124\\uC815\\uD574 \\uC8FC\\uC5C8\\uB2E4.\\ninput\\uC744 \\uCD5C\\uB300 \\uAE38\\uC774\\uB85C padding \\uD574\\uC8FC\\uC5C8\\uAE30 \\uB54C\\uBB38\\uC5D0 \\uACC4\\uC0B0 \\uD6A8\\uC728\\uC744 \\uC704\\uD574 attention_mask \\uC5ED\\uC2DC \\uD65C\\uC6A9.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"label\\uC740 loss \\uACC4\\uC0B0 \\uB2F9\\uC2DC \\uB3D9\\uC77C\\uD55C input\\uACFC \\uB3D9\\uC77C\\uD55C \\uAE38\\uC774\\uAC00 \\uC544\\uB2C8\\uBA74 \\uC624\\uB958\\uAC00 \\uBC1C\\uC0DD\\uD574\\uC11C \\uB611\\uAC19\\uC774 1024\\uB85C \\uC124\\uC815 \\uD574\\uC8FC\\uC5C8\\uB2E4.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"from torch.utils.data import DataLoader, TensorDataset\\n\\nbatch_size = 4\\n\\ndef preprocess(examples):\\n    inputs = tokenizer(examples['article'], return_tensors='pt', max_length=1024, padding='max_length', truncation=True)\\n    labels = tokenizer(examples['abstractive'], return_tensors='pt', max_length=1024, padding='max_length', truncation=True)\\n    inputs['labels'] = labels['input_ids']\\n    return inputs\\n\\ndef create_dataloader(dataset):\\n    input_ids = dataset['input_ids']\\n    attention_mask = dataset['attention_mask']\\n    labels = dataset['labels']\\n    tensor_dataset = TensorDataset(input_ids, attention_mask, labels)\\n    return DataLoader(tensor_dataset, batch_size=batch_size)\\n\\nif creates_dataset:\\n    dataloader = {\\n        'train': create_dataloader(train_dataset.map(preprocess, batched=True).with_format(\\\"torch\\\")),\\n        'val': create_dataloader(val_dataset.map(preprocess, batched=True).with_format(\\\"torch\\\"))\\n    }\\n    torch.save(dataloader, dataset_file)\\nelse:\\n    dataloader = torch.load(dataset_file)\\n\")), mdx(\"h1\", {\n    \"id\": \"train\"\n  }, \"Train\"), mdx(\"p\", null, \"validation dataset \\uC790\\uCCB4\\uB3C4 \\uC57D 30,000\\uAC1C \\uB370\\uC774\\uD130\\uB85C \\uC774\\uB8E8\\uC5B4\\uC838 \\uC788\\uC5B4 \\uD3C9\\uAC00 \\uC2DC\\uAC04\\uC774 \\uC624\\uB798 \\uAC78\\uB9AC\\uC9C0\\uB9CC \\uB354 \\uC815\\uD655\\uD55C \\uCE21\\uC815\\uC744 \\uC704\\uD574 sampling\\uC740 \\uD558\\uC9C0 \\uC54A\\uB294 \\uAC83\\uC73C\\uB85C \\uD558\\uC600\\uB2E4.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# evaluate model\\nfrom tqdm import tqdm\\n\\n@torch.no_grad()\\ndef eval_model(model, val_dataloader):\\n    device = next(model.parameters()).device\\n    model.to(device)\\n    model.eval()\\n    total_loss = 0\\n    \\n    print('=== evaluate model')\\n    for _, data in enumerate(tqdm(val_dataloader)):\\n        data = [t.to(device) for t in data]\\n        inputs = {\\n            'input_ids': data[0],\\n            'attention_mask': data[1],\\n            'labels': data[2]\\n        }\\n        outputs =  model(**inputs)\\n        loss = outputs.loss\\n        total_loss += loss.item()\\n    \\n    total_loss /= len(val_dataloader)\\n    print(f'total loss : {total_loss}')\\n    \\n    return total_loss\\n\")), mdx(\"p\", null, \"\\uD559\\uC2B5\\uC5D0\\uB294 epoch\\uB9C8\\uB2E4 \\uC120\\uD615\\uC801\\uC73C\\uB85C learning rate\\uB97C \\uAC10\\uC18C\\uC2DC\\uD0A4\\uB294 scheduler\\uB97C \\uC0AC\\uC6A9\\uD558\\uC600\\uB2E4.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"1 \\uC0AC\\uC774\\uD074 \\uD559\\uC2B5 \\uD558\\uB294\\uB370 \\uD558\\uB8E8\\uAC00 \\uAC78\\uB824\\uC11C checkpoint\\uB97C \\uB9CC\\uB4E4 \\uD544\\uC694\\uAC00 \\uC788\\uC5C8\\uB2E4.\\n\\uB610\\uD55C \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"yolov8\"), \" \\uBAA8\\uB378\\uC5D0\\uC11C \\uBCF8 \\uC804\\uB7B5\\uC778\\uB370, 1 \\uC0AC\\uC774\\uD074\\uB9C8\\uB2E4 \\uD3C9\\uAC00\\uB97C \\uC9C4\\uD589\\uD558\\uACE0 \\uAC00\\uC7A5 \\uB192\\uC740 \\uC810\\uC218\\uB97C \\uBC1B\\uC740 \\uB370\\uC774\\uD130\\uB97C best\\uB85C \\uB530\\uB85C \\uC800\\uC7A5\\uD574\\uB450\\uB294 \\uC804\\uB7B5\\uC744 \\uC0AC\\uC6A9 \\uD560 \\uAC83\\uC774\\uB2E4.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"\\uADF8\\uB9AC\\uACE0 \\uD559\\uC2B5\\uB41C \\uBAA8\\uB378 weight\\uB97C \\uC9C1\\uC811 \\uD30C\\uC77C\\uB85C \\uC804\\uB2EC\\uD558\\uC9C0 \\uC54A\\uACE0 hub\\uB97C \\uD1B5\\uD574 \\uC811\\uADFC \\uAC00\\uB2A5\\uD558\\uB3C4\\uB85D 1 \\uC0AC\\uC774\\uD074\\uC774 \\uB05D\\uB0A0 \\uB54C \\uB9C8\\uB2E4 huggingface\\uC5D0 push\\uD558\\uB294 \\uC791\\uC5C5\\uC744 \\uCD94\\uAC00\\uD55C\\uB2E4.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# train model\\nimport os\\nfrom torch.optim import AdamW, lr_scheduler\\n\\nclass Checkpoint():\\n    def __init__(self, model, optimizer, scheduler) -> None:\\n        self.model = model\\n        self.optimizer = optimizer\\n        self.scheduler = scheduler\\n        self.epoch = 0\\n        self.last_step = -1\\n        self.best_loss = 1e20\\n        \\n    def set_root_dir(self, root_dir):\\n        if root_dir is not None:\\n            self.root_dir = root_dir\\n            self.path = os.path.join(root_dir, 'checkpoint.pt')\\n            \\n            if not os.path.exists(root_dir):\\n                os.makedirs(root_dir)\\n                \\n            if os.path.exists(self.path):\\n                self.load(self.path)\\n    \\n    def load(self, save_path):\\n        checkpoint = torch.load(save_path)\\n        self.model.load_state_dict(checkpoint['model'])\\n        self.optimizer.load_state_dict(checkpoint['optimizer'])\\n        self.scheduler.load_state_dict(checkpoint['scheduler'])\\n        self.epoch = checkpoint['epoch']\\n        self.last_step = checkpoint['last_step']\\n        self.best_loss = checkpoint['best_loss']\\n    \\n    def save(self):\\n        if not self.path is None:\\n            torch.save({\\n                'model' : self.model.state_dict(),\\n                'optimizer' : self.optimizer.state_dict(),\\n                'scheduler' : self.scheduler.state_dict(),\\n                'epoch' : self.epoch,\\n                'last_step' : self.last_step,\\n                'best_loss' : self.best_loss\\n            }, self.path)\\n        \\n    def step(self):\\n        self.optimizer.step()\\n        self.last_step += 1\\n    \\n    def eval(self, val_dataloader):\\n        if not self.root_dir is None:\\n            loss = eval_model(self.model, val_dataloader)\\n            if self.loss > loss:\\n                self.loss = loss\\n                torch.save(self.model.state_dict(), os.path.join(self.root_dir, 'best.pt'))\\n    \\n    def next(self):\\n        self.scheduler.step()\\n        self.epoch += 1\\n        self.last_step = -1\\n        self.save()\\n        self.model.push_to_hub('yeti-s/kobart-base-v2-news-summarization', token=WRITE_TOKEN)\\n        \\n    def close(self):\\n        if not self.path is None and os.path.exists(self.path):\\n            os.remove(self.path)\\n\\n\\ndef train_model(model, dataloader, checkpoint_dir=None, epochs=1, lr=2e-5, device=torch.device('cuda')):\\n    model.to(device)\\n    optimizer = AdamW(model.parameters(), lr=lr)\\n    scheduler = lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda=lambda epoch:0.95**epoch)\\n    checkpoint = Checkpoint(model, optimizer, scheduler)\\n    checkpoint.set_root_dir(checkpoint_dir)\\n\\n    for epoch in range(checkpoint.epoch, epochs):\\n        print(f'=== train model {epoch}/{epochs}')\\n        model.train()\\n        num_trained = 0\\n        total_loss = 0\\n        \\n        for step, data in enumerate(tqdm(dataloader['train'])):\\n            if step <= checkpoint.last_step:\\n                continue\\n            \\n            data = [t.to(device) for t in data]\\n            inputs = {\\n                'input_ids': data[0],\\n                'attention_mask': data[1],\\n                'labels': data[2]\\n            }\\n\\n            # get loss\\n            optimizer.zero_grad()\\n            outputs =  model(**inputs)\\n            loss = outputs.loss\\n            total_loss += loss.item()\\n            \\n            loss.backward()\\n            checkpoint.step()\\n            num_trained += 1\\n            \\n            # save checkpoint \\n            if (step+1) % 1000 == 0:\\n                checkpoint.save()\\n                print(f'loss : {total_loss/num_trained}')\\n        \\n        checkpoint.eval(dataloader['val'])\\n        checkpoint.next()\\n        \\n    # remove checkpoint\\n    checkpoint.close()\\n\")));\n}\n;\nMDXContent.isMDXComponent = true;","tableOfContents":{"items":[{"url":"#base-모델-선정","title":"Base 모델 선정"},{"url":"#dataset","title":"Dataset"},{"url":"#train","title":"Train"}]},"frontmatter":{"title":"Summarization Module","description":"Summarize news content"}}},"pageContext":{"id":"fdd344dc-18c3-54d2-b18a-7772adc92468"}},"staticQueryHashes":["2575348879","2936798523","2940813629"]}