{"componentChunkName":"component---src-components-templates-main-template-tsx-content-file-path-contents-pill-recognizer-shape-detect-mdx","path":"/c1b44518-494d-5ab5-9007-e9d1b499a1fb","result":{"data":{"mdx":{"id":"c1b44518-494d-5ab5-9007-e9d1b499a1fb","body":"\r\n사진으로부터 알약을 찾고 형태를 분류하는 모듈을 만들거에요.\r\n\r\n# 초기 개발\r\n\r\n우리는 Yolo v8이라는 훌륭한 탐지 모델을 사용할 것입니다.\r\n그 전에 먼저 학습 데이터를 생성 해야겠죠?\r\n\r\n## 데이터 생성\r\n\r\n우리는 잘 정제된 알약 사진에서 알약의 위치를 Box의 형태로 생성해야 합니다.\r\n\r\n일단 먼저 배경을 제거하는 작업을 시작할까요?\r\n이미지의 픽셀중 가장 많이 나타나는 RGB값을 이용하여 배경색을 구했어요.\r\n이제 이미지에서 해당 RGB와 오차범위(3) 안쪽에 있는 값을 가지는 픽셀들을 전부 제거하고 남은 부분을 볼거에요.\r\n\r\n```python\r\n# get background color\r\nmost_b = get_most_value(img[:,:,0])\r\nmost_g = get_most_value(img[:,:,1])\r\nmost_r = get_most_value(img[:,:,2])\r\nbg_bgr = np.array([most_b, most_g, most_r])\r\n\r\n# filter background\r\nbackground = cv2.inRange(img, bg_bgr-3, bg_bgr+3)\r\nfiltered = background + 1\r\nfiltered[filtered > 0] = 255\r\nshape = img.shape\r\n```\r\n\r\n배경을 제거하니 알약, 알약 크기와 정보 출처에 관한 텍스트, 그리고 격자 무늬가 남아있네요.\r\n일단 무늬를 제거하는 코드를 만들어 봅시다.\r\n격자를 제거하기 위해 edge를 표시해주는 Laplacian Filter를 이용할게요.\r\n그런데 격자 무늬가 1~5px로 두꺼운 사진도 있기 때문에 이 과정을 5번 정도 반복해서 완전히 제거합시다.\r\n\r\n```python\r\n# filter edges\r\nfor i in range(5):\r\n    edges = cv2.Laplacian(filtered, cv2.CV_8U, ksize=3)\r\n    edges[:shape[0]-1,:shape[1]-1] = edges[1:,1:]\r\n    filtered[edges>0] = 0\r\n``` \r\n\r\n격자를 제거하고 나니 알약의 형태와 몇몇 텍스트만 남았네요.\r\n이제 외곽선을 검출하는 함수인 `findContours`를 이용하여 남은 객체들의 대략적인 형태를 가져오죠.\r\n그런데 우리가 관심있는 부분은 알약뿐 텍스트에 대해서는 필요가 없어요.\r\n그래서 검출된 외곽선의 넓이와 높이를 구해 일정 크기가 넘지 않으면 제거해서 알약만 남겨봅시다.\r\n\r\n```python\r\n# get contorus\r\ncontours, _ = cv2.findContours(filtered, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\r\n\r\n# filter contorus\r\nboxes = []\r\nthreshold = 100 # minimum width & height\r\nfor contour in contours:\r\n    min_x = np.min(contour[:,:,0])\r\n    max_x = np.max(contour[:,:,0])\r\n    min_y = np.min(contour[:,:,1])\r\n    max_y = np.max(contour[:,:,1])\r\n    width = max_x - min_x + 5 # correction for laplacian filter\r\n    height = max_y - min_y + 5 # correction for laplacian filter\r\n    \r\n    if width >= threshold and height >= threshold:\r\n        # center_x, center_y, width, height\r\n        boxes.append([(min_x+max_x)/2, (min_y+max_y)/2, width, height])\r\n```\r\n\r\n위 좌표를 이용해서 알약이 어느 위치에 있는지 우리는 알 수 있게 되었어요.\r\n\r\n![pipeline for creating label](assets/shape_detect/00.png)\r\n\r\n## 학습\r\n\r\n[train YOLOv8 on custom dataset](https://learnopencv.com/train-yolov8-on-custom-dataset/)\r\n\r\n우리는 YOLO를 사용하여 학습 및 추론을 진행 해볼게요.\r\n먼저 전에 생성한 데이터를 각각 train, test, validation 으로 나눠줍시다.\r\n그리고 학습을 위해 데이터 위치와 Class에 대한 정보를 .yaml 파일로 생성하여 학습에 대한 메타 데이터를 표시할 것입니다.\r\n\r\n```yaml\r\n# pill.yaml\r\npath: ./\r\ntrain: train/\r\nval: val/\r\n\r\nnc: 11\r\n\r\n# Classes\r\nnames:\r\n  0: '기타'\r\n  1: '마름모형'\r\n  2: '반원형'\r\n  3: '사각형'\r\n  4: '삼각형'\r\n  5: '오각형'\r\n  6: '원형'\r\n  7: '육각형'\r\n  8: '장방형'\r\n  9: '타원형'\r\n  10: '팔각형'\r\n```\r\n\r\n데이터의 폴더 구조는 아래와 같이 있어야 해요.\r\n```\r\n|-- train\r\n|   |-- images\r\n|       |-- 199101028.jpg\r\n|       |-- 199101035.jpg\r\n|   |-- labels\r\n|       |-- 199101028.txt\r\n|       |-- 199101035.txt\r\n|-- val\r\n|   |-- images\r\n|       |-- 195900032.jpg\r\n|       |-- 195900043.jpg\r\n|   |-- labels\r\n|       |-- 195900032.txt\r\n|       |-- 195900043.txt\r\n```\r\n\r\nlabel.txt의 내용은 `class_num center_x center_y width height`의 형태를 가져야 합니다.\r\n```\r\n8 0.7286374133949192 0.4421720733427362 0.34026173979984603 0.2397743300423131\r\n8 0.27251732101616627 0.4421720733427362 0.3394919168591224 0.24259520451339917\r\n```\r\n\r\n이제 관련된 패키지를 설치하고 학습을 진행해보죠\r\n\r\n```shell\r\n$ pip install ultralytics\r\n```\r\n\r\n```shell\r\n$ yolo task=detect mode=train model=yolov8n.pt imgsz=640 data=pill.yaml epochs=10 batch=8 name=yolov8n_pill\r\n```\r\n\r\n음 약 2시간 정도 기다렸더니 뭔가 폴더가 만들어 졌어요.\r\n안에 내용을 확인하니 score에 대한 그래프, validation 결과, best와 last 모델 weight 등이 저장되어 있네요.\r\n\r\n![val result](assets/shape_detect/01.jpg)\r\n\r\n학습 과정에서 validation dataset을 이용하여 진행한 평가의 일부 결과입니다.\r\n대충 어느정도 예측이 잘 진행되는데, 왼쪽 아래 붕어빵 모양 알약은 틀리게 예측되는 것도 있네요.\r\n아무튼 이런 방식으로 학습을 진행하면 될 것 같아요.\r\n\r\n## 추론\r\n\r\n학습된 모델을 활용해서 직접 test dataset을 활용하여 추론하는 과정을 연습해보죠.\r\n\r\n우리는 학습된 모델을 불러올 것이에요.\r\n```python\r\nfrom ultralytics import YOLO\r\nmodel = YOLO(\"runs/detect/yolov8n_shape/weight/best.pt\").cuda()\r\n```\r\n\r\n테스트 해볼 이미지도 함께 불러봅시다\r\n```python\r\nimport matplotlib.pyplot as plt\r\n\r\ndef imshow(img):\r\n    plt.imshow(img)\r\n    plt.axis('off')\r\n    plt.show()\r\n\r\nimg_path = 'test/images/197600554.jpg'\r\nimg = plt.imread(img)\r\nimshow(img)\r\n```\r\n\r\n![test image](assets/shape_detect/02.png)\r\n\r\n그럼 이제 모델을 이용해서 예측을 해보죠.\r\n```python\r\nresults = model.predict(img)  # predict on an image\r\n\r\nfor result in results:\r\n    names = result.names\r\n    boxes = result.boxes\r\n    for box in boxes:\r\n        pred = box.cls\r\n        conf = box.conf\r\n        print(f'shape: {names[pred.item()]}, confidence: {conf.item()}')\r\n        \r\n        xyxy = box.xyxy\r\n        min_x = round(xyxy[0][0].item())\r\n        min_y = round(xyxy[0][1].item())\r\n        max_x = round(xyxy[0][2].item())\r\n        max_y = round(xyxy[0][3].item())\r\n        imshow(img[min_y:max_y,min_x:max_x])\r\n```\r\n\r\n![prediction result](assets/shape_detect/03.png)\r\n\r\n![prediction result](assets/shape_detect/04.jpg)\r\n\r\n분명 이미지 속 알약은 둘인데 3개의 알약이 감지 되었네요.\r\n사실 깔끔한 이미지만을 이용하여 학습을 하는 것은 일반적인 상황에서 실용적이지 못할 것이라고 에상은 했어요.\r\n그래서 이 모듈을 더욱 개선시키기 위해서는 이미지를 회전하고, 이동시켜보고, 배경도 바꾸는 식의 Augmentation을 해야 할 것입니다.","tableOfContents":{"items":[{"url":"#초기-개발","title":"초기 개발","items":[{"url":"#데이터-생성","title":"데이터 생성"},{"url":"#학습","title":"학습"},{"url":"#추론","title":"추론"}]}]},"frontmatter":{"description":"Detect pill from picture and classify shape","title":"Detect & Shape"}},"file":{"modifiedTime":"2023-12-15T15:14:43.623Z"}},"pageContext":{"id":"c1b44518-494d-5ab5-9007-e9d1b499a1fb","relativePath":"pill_recognizer/shape_detect.mdx","frontmatter":{"title":"Detect & Shape","description":"Detect pill from picture and classify shape"}}},"staticQueryHashes":["123912876","2317542362"],"slicesMap":{}}