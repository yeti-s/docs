{"componentChunkName":"component---src-components-templates-main-template-tsx-content-file-path-contents-cs-cv-feature-tracking-feature-tracking-mdx","path":"/컴퓨터 비전/Feature Tracking","result":{"data":{"mdx":{"id":"3ce8b4b9-5365-5c40-8f66-879eaa4f0a82","body":"\r\n## Feature Tracking\r\n동영상과 같은 연속적인 이미지에 대해서 feature를 추출하고 tracking 하는 것에는 아래와 같은 어려움이 있다.\r\n* 몇몇 point는 시간이 지나면서 변화한다. (회전, 그림자 등)\r\n* Drift (small errors can accumulate as appearance model is updated)\r\n* Point가 나타나거나 사라질 수 있다.\r\n![feature moving](00.png)\r\n\r\n다음 시퀀스에서 feature의 이동을 계산하기 위해서 우리는 아래와 같은 가정을 한다.\r\n* Brightness constancy - 동일한 faeture는 동일하거나 비슷한 색을 가진다.\r\n* Small motion - point가 많이 움직이지 않는다.\r\n* Spatial coherence - point가 그 주변 point들과 비슷하게 움직인다.\r\n\r\n## Brightness constancy + Small motion\r\nBrightness constancy와 Small motion 특징에 의해 다음 시퀀스에서도 아주 조금 움직이고 동일한 밝기를 가진다고 하면 아래와 같이 표현할 수 있다.\r\n$$\r\nI(x,y,t) = I(x+u,y+v,t+1)\r\n$$\r\n위 식을 N=1인 Taylor Series를 적용하면\r\n$$\r\nI(x+u,y+v,t+1) \\approx I(x,y,t) + I_xu+I_yv+I_t\r\n$$\r\n$$\r\nI_xu+I_yv+I_t = 0\r\n$$\r\n으로 근사할 수 있다.  \r\n이 때 $[u, v]$는 motion vector, $[I_x, I_y]$는 gradient vector, $I_t=I(x,y,t+1)-I(x,y,t)$이다.\r\n\r\n## Lucas-Kanade Method\r\n위 식만을 가지고는 motion vector를 구할 수 없다.\r\n하지만 Spatial coherence 특징을 생각하면 주변의 point들 역시 동일한 움직임을 했다고 생각해보자.\r\nfeature point 주변 5x5 window를 구성하고 내부 점들은 같은 움직임을 보인다고 하면 아래와 같이 표현할 수 있다.\r\n$$\r\nI_x(p_1)+I_y(p_1)=-I_t(p_1)\r\n$$\r\n$$\r\nI_x(p_2)+I_y(p_2)=-I_t(p_2)\r\n$$\r\n$$\r\n\\vdots\r\n$$\r\n$$\r\nI_x(p_25)+I_y(p_25)=-I_t(p_25)\r\n$$\r\n이를 행렬로 표현하면\r\n$$\r\n\\begin{bmatrix}\r\nI_x(p_1) & I_y(p_1) \\\\\r\nI_x(p_2) & I_y(p_2) \\\\\r\n\\vdots & \\vdots \\\\\r\nI_x(p_25) & I_y(p_25) \\\\\r\n\\end{bmatrix}\r\n\\begin{bmatrix}\r\nu \\\\\r\nv \\\\\r\n\\end{bmatrix}\r\n=-\r\n\\begin{bmatrix}\r\nI_t(p_1)\\\\\r\nI_t(p_2) \\\\\r\n\\vdots \\\\\r\nI_t(p_25)\\\\\r\n\\end{bmatrix}\r\n$$\r\n위 $Ad=b$ 형태의 행렬을 $(A^TA)d=A^Tb$ 형태로 표현하면 아래와 같다.\r\n$$\r\n\\begin{bmatrix}\r\n\\sum I_xI_x & \\sum I_xI_y \\\\\r\n\\sum I_xI_x & \\sum I_yI_y \\\\\r\n\\end{bmatrix}\r\n\\begin{bmatrix}\r\nu \\\\\r\nv \\\\\r\n\\end{bmatrix}\r\n=-\r\n\\begin{bmatrix}\r\n\\sum I_xI_t\r\n\\sum I_yI_x\r\n\\end{bmatrix}\r\n$$\r\nu,v를 구하기 위해서는 아래와 같은 조건이 필요하다\r\n* $A^TA$ should be invertible (역행렬이 존재)\r\n* $A^TA$ should not be too small due to noise ($A^TA$의 eigenvalue $\\lambda_min$이 너무 작으면 안됨)\r\n* $A^TA$ should be well-conditioned ($\\lambda_max / \\lambda_min$ 가 너무 크면 안됨 -> 계산 오차가 커질 수 있다고 함)\r\n\r\n위 방법은 window size에 의해 영향을 받는다.  \r\n너무 작으면 noise에 민감해진다.\r\n또한 window보다 큰 움직임은 계산하지 못한다.  \r\n너무 크면 배경과 물체가 다르게 움직이는 등 상황에 따라 오차가 발생한다.\r\n또한 계산 비용이 증가한다.\r\n\r\n\r\n![pyramid tracking](01.png)\r\n현실적으로 큰 Object에 대해서 tracking을 시도하는 경우가 많다.\r\n하지만 위 방법은 작은 window 사이즈로 small motion을 가정하기 때문에 그림처럼 축소한 후 작은 사이즈부터 tracking을 하는 것으로 진행할 수 있다.\r\n\r\n## Optical flow\r\nBrightness 패턴의 움직임을 추정하는 것이다.\r\n이는 Object의 모션 움직임 뿐 아니라 카메라 이동등에 따른 이미지 Translation과 같은 것도 추정한다.\r\nOptical flow는 아래 그림처럼 움직임에 따라 색으로 표현한다.\r\n![optical flow color](02.png)\r\n\r\nOptical flow는 모든 포인트를 feature로 Lucas-Kanade equation을 적용한다.\r\n큰 모션을 다루기 위해서는 coarse-to-fine 로 접근한다. (coarse-to-file은 한가지 작업을 더 작은 부분으로 나누어 각 부분을 자세하게 살펴보는 것)\r\n\r\n그러나 모든 픽셀으로 연산을 해야 하기에 많은 연산량이 필요하다.  \r\n그래서 GPU와 같은 병렬 연산이 필요하다.  \r\n또 flat이나 edge region의 경우는 추정 불가능하다. (Lucas-Kanade 역행렬이 존재 x)  \r\n부가적인 smooth regularization이 필요하다.\r\n\r\n요즘에는 FlowNet과 같은 deep learning으로 하고 있기도 하다.\r\n\r\n## 응용\r\n* Estimating 3D structure\r\n* Segmenting objects based on motion cues (motion segmentation)\r\n* Learning and tracking dynamical models\r\n* Recognizing events and activities\r\n* Improving video quality (motion stabilization) - 카메라 흔들림 같은거 예측","tableOfContents":{"items":[{"url":"#feature-tracking","title":"Feature Tracking"},{"url":"#brightness-constancy--small-motion","title":"Brightness constancy + Small motion"},{"url":"#lucas-kanade-method","title":"Lucas-Kanade Method"},{"url":"#optical-flow","title":"Optical flow"},{"url":"#응용","title":"응용"}]},"frontmatter":{"description":"SIFT, feature descriptors and matching","title":"Feature Tracking","date":"2023년 12월 11일"}}},"pageContext":{"id":"3ce8b4b9-5365-5c40-8f66-879eaa4f0a82","frontmatter":{"title":"Feature Tracking","description":"SIFT, feature descriptors and matching","date":"2023년 12월 11일","subject":"컴퓨터 비전","visible":true,"order":4}}},"staticQueryHashes":["1569657708","2317542362"],"slicesMap":{}}