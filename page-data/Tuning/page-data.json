{"componentChunkName":"component---src-components-templates-main-template-tsx-content-file-path-contents-paper-tuning-index-index-mdx","path":"/Tuning","result":{"data":{"mdx":{"id":"f25f35dd-5e08-5967-aa3e-c0da85417904","body":"\r\nimport * as Elem from '@elements';\r\n\r\nimport LORA from './LoRA.png';\r\n\r\n\r\nLLM 모델을 튜닝하는 효과적인 방법에 대한 논문들을 다룹니다.\r\n\r\n# 논문\r\n\r\n<Elem.CardContainer>\r\n    <Elem.Card src={LORA} \r\n          title='LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS' \r\n          description='LLM을 효율적으로 Fine-tuning 하는 방법에 대해 설명합니다.' \r\n          path={'Integer Arithm Only Quant and Train'}/>\r\n</Elem.CardContainer>\r\n","tableOfContents":{"items":[{"url":"#논문","title":"논문"}]},"frontmatter":{"description":"Tuning for Large Language Model","title":"Tuning","date":"2024년 3월 19일"}}},"pageContext":{"id":"f25f35dd-5e08-5967-aa3e-c0da85417904","frontmatter":{"title":"Tuning","description":"Tuning for Large Language Model","date":"2024년 3월 19일","category":"PAPER","visible":true}}},"staticQueryHashes":["1569657708","2317542362"],"slicesMap":{}}