{"componentChunkName":"component---src-components-templates-main-template-tsx-content-file-path-contents-remind-research-mdx","path":"/bdd6b7fb-81e3-50c2-a73c-66e4de03326a","result":{"data":{"mdx":{"id":"bdd6b7fb-81e3-50c2-a73c-66e4de03326a","body":"\r\nimport ColorText from '@contents/components/ColorText';\r\nimport Comment from '@contents/components/Comment';\r\n\r\n`프로젝트 리마인드`를 개발하기 위해 필요한 기술에 대해 조사를 진행합니다.\r\n\r\n# 음성 합성\r\n\r\n`프로젝트 리마인드`에서 핵심 기술을 구현하기 위해, LLM과 프롬프트 엔지니어링을 활용한 응답 생성과 음성을 합성하여 문장을 음성 데이터로 변환하는 기술이 필요합니다.\r\n기존의 음성 합성에 대한 도메인이 하나도 존재하지 않았기에 관련 연구를 찾아보았습니다.\r\n\r\n## Tacotron\r\n\r\n`Tacotron`은 구글에서 개발한 텍스트를 음성으로 변환하는 End-to-End 음성 합성 시스템입니다.\r\n강세, 억양, 리듬과 같은 자연스러운 음성을 재현하는 작업을 수행하여 대상의 목소리와 비슷한 음성을 생성합니다.\r\n\r\n<Comment>\r\n여러 논문을 찾아보았지만 Tacotron를 실제 서비스에 직접 활용하기 보다 기본적으로 Tacotron을 이용하여 발전시킨 모델들을 활용하는 듯!\r\n약간 음성에 대한 기본 배경 지식이라 생각하고 공부만 간단하게 하고 다른 모델을 봐야 할 듯!\r\n</Comment>\r\n\r\n## 커스텀 음성 합성기\r\n\r\n🤔 음성 합성기를 조사하다 보니 의문이 생기더라구요.  \r\n위에서 언급했던 음성 합성 방법들은 특정한 목소리를 기반으로 TTS를 구현하는 것을 목표로 모델을 최적화합니다.\r\n이를 `프로젝트 리마인드`에 적용하게 된다면 사용자 개개인에 맞춰 모델을 학습시키고 보관하는 비용이 발생할 것이죠.\r\n하나의 모델로 다양한 화자의 목소리를 만들어 낼 수 있는 기술이 필요할 것 같다고 느꼈습니다.\r\n\r\n<p style={{textAlign: \"center\"}}>\r\n`youtube: https://www.youtube.com/watch?v=enBn77LIC24`\r\n`카카오엔터프라이즈 커스텀 음성 합성 기술`\r\n</p>\r\n\r\n`다화자 합성기`는 선택된 화자의 목소리로 합성음을 출력하는 모델입니다.\r\n이는 공통된 Encoder, Decoder와 화자 개개인의 고유 음성 정보로 구성되는데,\r\n공통된 Encoder와 Decoder를 사용하기 때문에 한명당 화자 고유 음성 정보를 구성하는데 필요한 문장 수가 줄어드는 특징이 있습니다.\r\n\r\n그런데 이는 <ColorText color='var(--error)'>화자를 추가하는 과정에서 기존에 존재하는 화자의 특성을 잃어버리는 문제가 발생할 수 있구요</ColorText>,\r\n또 기존 모델을 구성하는 비용에 비해 신규 화자의 음성 데이터가 적을 뿐 <ColorText color='var(--error)'>많은 문장의 데이터가 필요한 것</ColorText>은 마찬가지 입니다.\r\n\r\n`카카오 엔터프라이즈`에서는 이를 해결하기 위해 다 만들어진 합성기에 목소리만 추가할 수 있는 `커스텀 음성 합성기`를 만들었다고 합니다.\r\n위 영상에서는 두 가지 방법을 통해 커스텀 음성 합성기에 목소리를 추가하고 있습니다.\r\n\r\n\r\n### 적응 기반 커스텀 합성기\r\n\r\n첫 번째는 [ADASPEECH](https://arxiv.org/pdf/2103.00993.pdf)를 적용하여 `적응 기반 커스텀 합성기`를 구축하는 방법입니다.\r\n`적응 기반 합성기`는 훈련이 완료된 `다화자 합성기`에 추가적인 훈련(적응)을 통해 목소리를 추가하는 방법입니다.\r\n일부 파라미터의 Backpropagation을 막아 Speaker Embedding의 파라미터만 조절하는 Parameter Tuning의 방식이죠.\r\n이는 목소리가 추가될 때 마다 추가적인 학습이 필요하다는 사실은 동일합니다.\r\n\r\n즉 1단계 - 다화자 TTS 훈련이 진행되고, 2단계 - 목적 화자로 정응 훈련을 진행하는 방식이죠.\r\n이 방식은 추가적인 적응 훈련이 필요하고, 적응 과정에서 업데이트 된 파라미터 저장 용량이 필요합니다.\r\n또 새로운 화자를 추가하기 위해 약 20문장으로 구성된 화자의 음성 데이터가 필요합니다. \r\n\r\n### Zero-Shot 커스텀 합성기\r\n\r\n`Zero-Shot 커스텀 합성기는` Speaker Encoder를 두어 새로운 화자의 목소리를 Encoding하여 사용할 수 있도록 만들어진 모델입니다.\r\n따라서 새로운 화자의 음성을 추가적인 학습 단계 없이 바로 사용할 수 있다는 장점이 있습니다.\r\n적게는 1문장의 화자 음성 데이터 만으로도 구축할 수 있다는 장점이 있죠.\r\n\r\n`프로젝트 리마인드`에서 다양한 사용자에 대한 여러 음성 데이터를 처리하기 위해서는 `Zero-Shot 커스텀 합성기`를 채택하는 것이 더 좋아보입니다.\r\n하지만 좋은 Speaker Encoder를 구성하는 방법을 잘 찾아봐야 할 것 같아요. \r\n\r\n\r\n# 언어 모델\r\n\r\n`프로젝트 리마인드`의 당사자의 말투와 화법을 고려한 응답을 생성하기 위해 LLM의 입력을 전달하기 전, 여러 프롬프트 엔지니어링 기술이 필요합니다.\r\nOpen AI는 서비스하고 있는 [ChatGPT의 Prompt Engineering](https://platform.openai.com/docs/guides/prompt-engineering) 정보를 제공하고 있죠.\r\n\r\n## LangChain\r\n\r\n[LangChain](https://aws.amazon.com/ko/what-is/langchain)은 LLM을 기반으로 어플리케이션을 구축하기 위한 오픈 소스 프레임워크입니다.\r\n모델이 생성하는 정보의 맞춤화, 정확성 및 관련성을 개선하기 위한 도구와 추상화 기능을 제공하죠.\r\n이를 활용하여 새 프롬프트 체인을 구축하거나 기존 템플릿을 커스텀하여 언어 모델의 개발을 간소화합니다.\r\n\r\n![](assets/research/lang_chain_architecture.png)\r\n\r\n`LangChain`에서 아래와 같은 기능을 제공하고 있습니다.\r\n\r\n* LLM 인터페이스  \r\n간단한 API를 통해 `GPT`, `Bard`, `PaLM` 모델을 간편하게 이용할 수 있습니다.\r\n* 프롬프트 템플릿  \r\nAI 모델에 일관된 요청을 보내도록 프롬프트 템플릿을 구성, 이용할 수 있습니다.\r\n* 에이전트  \r\n언어 모델이 요청에 응답하는 최상의 시퀀스를 결정하도록 유도하는 체인입니다.\r\n<Comment>\r\nDecoding 방법을 의미하는 건가? 조금 더 찾아봐야 할 듯!\r\n</Comment>\r\n* 검색 모듈  \r\n`RAG` 시스템을 설계할 수 있습니다. (여기서 쓸 일은 없을 듯 하지만 다른 업무에선 활용 가치 높을 듯!)\r\n* 메모리  \r\n대화형 언어 모델에서 이전 대화를 기억하는 간단한 메모리 시스템과 과거 메세지를 분석하여 가장 연관성이 높은 결과를 반환하는 복잡한 메모리 구조를 제공합니다.\r\n* 콜백  \r\n작업의 이벤트를 기록, 모니터링, 스트리밍 기능을 추가하여 오류를 추적할 수 있습니다.\r\n\r\n<p style={{textAlign: \"center\"}}>\r\n`youtube: https://www.youtube.com/watch?v=EWKbZFqiCsE`\r\n`랭체인으로 수익형 AI 웹서비스 만들기`\r\n</p>","tableOfContents":{"items":[{"url":"#음성-합성","title":"음성 합성","items":[{"url":"#tacotron","title":"Tacotron"},{"url":"#커스텀-음성-합성기","title":"커스텀 음성 합성기"}]},{"url":"#언어-모델","title":"언어 모델","items":[{"url":"#langchain","title":"LangChain"}]}]},"frontmatter":{"description":"프로젝트 리마인드 조사","title":"필요 기술 조사","date":"2023년 1월 10일"}}},"pageContext":{"id":"bdd6b7fb-81e3-50c2-a73c-66e4de03326a","relativePath":"remind/research.mdx","frontmatter":{"title":"필요 기술 조사","description":"프로젝트 리마인드 조사","subject":"프로젝트","visible":true,"date":"2023년 1월 10일","order":2}}},"staticQueryHashes":["2317542362","2468140611"],"slicesMap":{}}