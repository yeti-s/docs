{"componentChunkName":"component---src-templates-docs-js","path":"/nlp_quant/smooth_quant","result":{"data":{"mdx":{"body":"var _excluded = [\"components\"];\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Smooth Quantization\",\n  \"description\": \"Accurate and Efficient Post-Training Quantization for Large Language Models\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"\\uB17C\\uBB38 \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"'https://arxiv.org/abs/2211.10438'\"\n  }, \"SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models\"), \" \\uB97C \\uBC14\\uD0D5\\uC73C\\uB85C \\uC791\\uC131\\uD558\\uC600\\uB2E4.\"), mdx(\"h2\", {\n    \"id\": \"llm-quantization의-어려움\"\n  }, \"LLM Quantization\\uC758 \\uC5B4\\uB824\\uC6C0\"), mdx(\"p\", null, \"LLM(Large Language Model)\\uC758 \\uACBD\\uC6B0 \\uC544\\uB798\\uC640 \\uAC19\\uC740 \\uD2B9\\uC9D5\\uC774 \\uC788\\uB2E4.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Weight\\uB294 \\uB300\\uCCB4\\uB85C \\uADE0\\uB4F1\\uD558\\uACE0 \\uACE0\\uB8E8 \\uBD84\\uD3EC\\uD558\\uB294 \\uD615\\uC0C1\\uC744 \\uAC00\\uC9C4\\uB2E4.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Activation\\uC758 outliers\\uB294 \\uB2E4\\uB978 \\uAC12\\uB4E4\\uBCF4\\uB2E4 ~100\\uBC30 \\uAE4C\\uC9C0\\uC758 \\uD070 \\uCC28\\uC774\\uB97C \\uAC00\\uC9C4\\uB2E4.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Activation\\uC5D0\\uC11C outlier\\uAC00 \\uBC1C\\uC0DD\\uD558\\uB294 Channel\\uC740 \\uB300\\uCCB4\\uB85C \\uC77C\\uC815\\uD558\\uB2E4.\")), mdx(\"p\", null, \"\\uC774\\uB294 per-channel quantization\\uC73C\\uB85C \\uC5B4\\uB290\\uC815\\uB3C4 \\uD574\\uACB0\\uC774 \\uAC00\\uB2A5\\uD558\\uC9C0\\uB9CC \\uD558\\uB4DC\\uC6E8\\uC5B4 \\uD2B9\\uC131\\uC0C1 \\uD574\\uB2F9 \\uC5F0\\uC0B0\\uC740 \\uBE44\\uD6A8\\uC728\\uC801\\uC774\\uB2E4.\\n('per-channel activation quantization does not map well to hardware-accelerated GEMM kernels.' \\uB77C\\uACE0 \\uC801\\uD600 \\uC788\\uB294\\uB370 \\uC790\\uC138\\uD788\\uB294 \\uC798 \\uBAA8\\uB974\\uACA0\\uC9C0\\uB9CC \\uD55C\\uBC88\\uC5D0 \\uBCD1\\uB82C \\uC5F0\\uC0B0\\uC774 \\uC548\\uB418\\uAE30 \\uB584\\uBB38\\uC778 \\uAC83 \\uAC19\\uB2E4.)\"), mdx(\"h2\", {\n    \"id\": \"아이디어\"\n  }, \"\\uC544\\uC774\\uB514\\uC5B4\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"704px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/09baf853f0a8a4f90786702e29fd0c47/3fca6/00_acts_weights_graph.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"31.818181818181817%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABj0lEQVQY0yWRPYsTURiF8yMs7WV/gNhYi1jYi9rYKwtiKaiNlsHG2sKF/QGBIIuuZkHDLpPFRIO7GyeTZDIfyWQ+MnPn3mQyj3eSW57LeXjPObVys6F6ycU/RBgjKVlEIbnISdMM257S7/cxTZMoiomTJVmWoZRio71KrchzSVEUlGVJrYI5zW80r99mpk1Wq82w0yVfKfIsJokDfN/T8BQpBVkaEmttuazAApkvEVmlLfS/pJZo4Pmz1xg39vAOPtC4dhO/bZCuC36cTvn1x8X1ApSGWeOQL60Rfy9dgiBipQSd3oyj72MuBx5Cp6oJCk7rnzh89IJ3d1/xee8OyXxG49jhwVODJ88NDfVIkoS377vce9hi/+UZ1sjhygx4vG9w6/4Jb+pdXUm0i+z7Ic2TMR/rx/i9PuuqBifg59mEdsfRPeloUukePb7qC897jo6a6tg5vd82jaMxg6HPeiV3QCky3NEVk6mF2hTbkeYLH3tqYk+G2662WuTp2BcEc283pIixHO1zB7iOvR3lP67jrPGTCMlAAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"00 acts weights graph\",\n    \"title\": \"00 acts weights graph\",\n    \"src\": \"/static/09baf853f0a8a4f90786702e29fd0c47/5ebd7/00_acts_weights_graph.png\",\n    \"srcSet\": [\"/static/09baf853f0a8a4f90786702e29fd0c47/06437/00_acts_weights_graph.png 176w\", \"/static/09baf853f0a8a4f90786702e29fd0c47/ba1c3/00_acts_weights_graph.png 352w\", \"/static/09baf853f0a8a4f90786702e29fd0c47/5ebd7/00_acts_weights_graph.png 704w\", \"/static/09baf853f0a8a4f90786702e29fd0c47/fd84e/00_acts_weights_graph.png 1056w\", \"/static/09baf853f0a8a4f90786702e29fd0c47/3fca6/00_acts_weights_graph.png 1112w\"],\n    \"sizes\": \"(max-width: 704px) 100vw, 704px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"p\", null, \"\\uC704 \\uADF8\\uB9BC\\uACFC \\uAC19\\uC774 \\uAE30\\uC874 Activation\\uC740 \\uD2B9\\uC815 channel\\uC5D0\\uC11C \\uD070 \\uAC12\\uC744 \\uAC00\\uC9C0\\uB294 \\uD2B9\\uC9D5\\uC774 \\uC788\\uB2E4.\\n\\uBC18\\uBA74\\uC5D0 weight\\uB294 \\uB300\\uCCB4\\uB85C \\uD3C9\\uD0C4\\uD558\\uAC8C \\uBD84\\uD3EC\\uD558\\uB294 \\uAC83\\uC744 \\uBCFC \\uC218 \\uC788\\uB2E4.\\n\\uC704 \\uC0C1\\uD0DC\\uB85C Quantization\\uC744 \\uC9C4\\uD589\\uD558\\uAC8C \\uB41C\\uB2E4\\uBA74 Activation\\uC758 \\uC18C\\uC218 Channel \\uB54C\\uBB38\\uC5D0 min max \\uAC12\\uC758 \\uCC28\\uC774\\uB294 \\uCEE4\\uC838 Quantization Error \\uC5ED\\uC2DC \\uCEE4\\uC9C0\\uAC8C \\uB41C\\uB2E4.\\n\\uADF8\\uB798\\uC11C Activation\\uC5D0\\uC11C \\uD070 \\uAC12\\uC744 \\uC9C0\\uB2C8\\uB294 Channel\\uB4E4\\uC758 \\uAC12\\uC744 \\uC791\\uAC8C \\uB9CC\\uB4DC\\uB294 \\uB300\\uC2E0 Weight\\uC5D0\\uC11C \\uD574\\uB2F9 Channel\\uACFC \\uC5F0\\uC0B0\\uC5D0 \\uAD00\\uC5EC\\uD558\\uB294 \\uBD80\\uBD84\\uC744 \\uC57D\\uAC04 \\uD06C\\uAC8C \\uB9CC\\uB4E4\\uC5B4 Quantization\\uC744 \\uC9C4\\uD589\\uD558\\uB294 \\uBC29\\uBC95\\uC774\\uB2E4.\\n\\uC904\\uC5B4\\uB4E4\\uC740 Activation\\uC740 min max \\uCC28\\uC774\\uAC00 \\uC904\\uC5B4\\uB4E4\\uC5B4 Quantization Error\\uAC00 \\uC904\\uC5B4\\uB4E4\\uAC8C \\uB418\\uACE0 Weight\\uB294 min max \\uCC28\\uC774\\uAC00 \\uC99D\\uAC00\\uD558\\uC9C0\\uB9CC \\uAE30\\uC874 Activation\\uC5D0\\uC11C \\uBC1C\\uC0DD\\uD55C Error\\uC5D0 \\uBE44\\uD574 \\uD06C\\uC9C0 \\uC54A\\uC544 \\uD6A8\\uC728\\uC774 \\uB354 \\uC88B\\uC544\\uC9C4\\uB2E4.\"), mdx(\"h2\", {\n    \"id\": \"방법\"\n  }, \"\\uBC29\\uBC95\"));\n}\n;\nMDXContent.isMDXComponent = true;","tableOfContents":{"items":[{"url":"#llm-quantization의-어려움","title":"LLM Quantization의 어려움"},{"url":"#아이디어","title":"아이디어"},{"url":"#방법","title":"방법"}]},"frontmatter":{"title":"Smooth Quantization","description":"Accurate and Efficient Post-Training Quantization for Large Language Models"}}},"pageContext":{"id":"fe5cf480-e2fd-5001-b362-b95701d9e47d"}},"staticQueryHashes":["2575348879","2936798523","2940813629"]}