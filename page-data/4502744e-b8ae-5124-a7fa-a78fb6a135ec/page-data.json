{"componentChunkName":"component---src-components-templates-main-template-tsx-content-file-path-contents-nlp-prompting-mdx","path":"/4502744e-b8ae-5124-a7fa-a78fb6a135ec","result":{"data":{"mdx":{"id":"4502744e-b8ae-5124-a7fa-a78fb6a135ec","body":"\r\n2018년 Open AI에서 `GPT(Generative Pretrained Transformer)`를 발표했어요.\r\n12개의 디코더 레이어와 7000 가지가 넘는 책을 통해 학습이 되었지요.\r\nGPT는 language modeling은 효과적인 사전 학습 방법이라는 것을 보여주었어요.\r\n\r\n2019년에는 GPT2가 공개되었어요.\r\n파라미터는 117M에서 1.5B로 늘었고, 40GB 되는 온라인 텍스트를 통해 사전 학습 되었어요.\r\n여기서 한가지 중요한 점은 `zero-shot learning`의 등장입니다.\r\n\r\n2020년에는 GPT3가 발표되었습니다.\r\n파라미터가 175B으로 늘었고, 학습된 데이터의 수도 600GB를 넘었습니다.\r\nGPT3에서 특징은 `few-shot learning`이 등장하였습니다.\r\n\r\n# Zero-shot, Few-shot learning\r\n\r\n`Zero-shot learning`은 우리가 학습시키지 않은 작업에 대해서도 작동하는 것을 의미합니다.\r\n예를 들면 우리는 그저 사전 학습만을 시켰으나, QA 작업에 대해서도 좋은 답변을 내놓은 것이죠.\r\nGPT2는 추가적인 fine-tuning 없이 기존의 task에서 높은 성능을 내어 여러 부문에서 SOTA를 달성하였어요.\r\n\r\n`Few-shot learning`은 하나의 작업을 수행하기 전 그 작업과 관련한 예시와 함께 넣어주는 것이에요.\r\n새로운 작업을 배울 때 가중치 업데이트가 일어나지 않는다고 하여 `in-context learning`이라고도 불립니다.\r\n\r\n![](assets/prompting/00.png)\r\n\r\n# Prompting\r\n\r\n특히 규모가 큰 모델에서 높은 정확도를 나타내는 것을 확인할 수 있었어요.\r\n가중치 업데이트 없이 새로운 작업을 수행시킬 수 있다는 발견으로 prompt에 대한 중요성이 대두되었습니다.\r\n하지만 여라 단계를 통한 추론과 같은 몇몇 작업들은 prompting 만으로는 어려움이 있었습니다.\r\n\r\n이를 해결하기 위해 나온 개념이 `CoT(Chain-of-Thought) Prompting`입니다.\r\n\r\n![](assets/prompting/01.png)\r\n\r\n위 그림과 같이 예시에 대한 해결 방식을 step by step으로 제시함으로 모델에게 prompt에 대한 이해도를 높입니다.\r\n이 방식은 모델의 규모가 클때 지도학습된 모델의 성능을 따라가는 결과를 볼 수 있었어요.\r\n이것을 조금 더 발전시켜 모델의 step by step 출력을 이용하여 prompt로 다시 제공하는 방식으로 원하는 답변을 얻을 수 있습니다.\r\n이를 `zero-shot chain-of-thought prompoting`이라고 해요.\r\n\r\n![](assets/prompting/02.png)","tableOfContents":{"items":[{"url":"#zero-shot-few-shot-learning","title":"Zero-shot, Few-shot learning"},{"url":"#prompting","title":"Prompting"}]},"frontmatter":{"description":"Prompting","title":"Prompting"}},"file":{"modifiedTime":"2023-12-16T09:20:30.149Z"}},"pageContext":{"id":"4502744e-b8ae-5124-a7fa-a78fb6a135ec","relativePath":"nlp/prompting.mdx","frontmatter":{"title":"Prompting","description":"Prompting","order":8}}},"staticQueryHashes":["123912876","2317542362"],"slicesMap":{}}