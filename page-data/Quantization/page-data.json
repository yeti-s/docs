{"componentChunkName":"component---src-components-templates-main-template-tsx-content-file-path-contents-paper-quantization-index-index-mdx","path":"/Quantization","result":{"data":{"mdx":{"id":"d9b27638-474c-5818-ad7b-bb6a4e4bc522","body":"\r\nimport * as Elem from '@elems';\r\n\r\nimport INT_ARITHM_ONLY from './int_arithm_only.png';\r\nimport SMOOTH_QUANT from './smooth_quant.png';\r\n\r\n딥러닝 모델의 Quantization에 대한 논문 내용을 다룹니다.\r\n\r\n# 논문\r\n\r\n<Elem.CardContainer>\r\n    <Elem.Card src={INT_ARITHM_ONLY} \r\n          title='Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference' \r\n          description='딥러닝 모델을 Integer 만을 이용하여 Quantization 및 Training 을 진행하는 방법에 대해 소개합니다.' \r\n          path={'Integer Arithm Only Quant and Train'}/>\r\n    <Elem.Card src={SMOOTH_QUANT} \r\n          title='SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models' \r\n          description='LLM에서 Activation의 특정 채널에서 이상값을 가지는 것을 기반으로 스케일링을 통해 효과적인 Quantization을 진행합니다.' \r\n          path={'SmoothQuant'}/>\r\n</Elem.CardContainer>\r\n","tableOfContents":{"items":[{"url":"#논문","title":"논문"}]},"frontmatter":{"description":"Quantization for Large Language Model","title":"Quantization","date":"2024년 2월 7일"}}},"pageContext":{"id":"d9b27638-474c-5818-ad7b-bb6a4e4bc522","frontmatter":{"title":"Quantization","description":"Quantization for Large Language Model","date":"2024년 2월 7일","category":"PAPER","visible":true}}},"staticQueryHashes":["1569657708","2317542362"],"slicesMap":{}}