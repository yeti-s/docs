"use strict";(self.webpackChunkyeti_docs=self.webpackChunkyeti_docs||[]).push([[852],{3832:function(e,t,r){var n=r(4316),a=(r(7294),r(917));const o=(0,n.Z)("code",{target:"e1h9msy90"})({name:"15yct12",styles:"display:block;width:100%;padding:0.2rem 0.4rem 0rem;color:var(--comment-color)"});t.Z=e=>{let{children:t}=e;return(0,a.tZ)(o,null,t)}},7933:function(e,t,r){r.r(t),r.d(t,{default:function(){return S}});var n=r(1151),a=r(7294),o=r(3832);function s(e){const t=Object.assign({p:"p",h1:"h1",ul:"ul",li:"li",a:"a",br:"br",pre:"pre",code:"code"},(0,n.ah)(),e.components);return a.createElement(a.Fragment,null,a.createElement(t.p,null,"기사의 내용을 통해 새로운 제목을 생성해주는 모듈을 개발합니다."),"\n",a.createElement(t.h1,{id:"base-모델-선정"},"Base 모델 선정"),"\n",a.createElement(t.p,null,"높은 한국어 인식율을 위해 문서 요약 모델로 채택된 BART의 한국어 문장으로 pre-trained 모델을 찾아보았어요."),"\n",a.createElement(t.ul,null,"\n",a.createElement(t.li,null,a.createElement(t.a,{href:"https://github.com/SKT-AI/KoBART"},"SKT-AI KoBART"),a.createElement(t.br),"\n","SKT에서 제공하는 KoBART는 여러가지 의존성을 추가로 설치해야해서 다른 모델을 더 찾아보고 결정하기로 할게요."),"\n",a.createElement(t.li,null,a.createElement(t.a,{href:"https://huggingface.co/gogamza/kobart-base-v2"},"gogamza/kobart-base-v2"),a.createElement(t.br),"\n","찾아보니 SKT-AI KoBART와 동일한 모델이 이미 올라온 듯 하여 이를 사용하기로 했습니다."),"\n"),"\n",a.createElement(t.pre,null,a.createElement(t.code,{className:"language-python"},"import torch\r\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\r\nmodel_name = 'gogamza/kobart-base-v2'\r\n\r\n# get model, tokenizer\r\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\r\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n")),"\n",a.createElement(t.h1,{id:"dataset"},"Dataset"),"\n",a.createElement(t.p,null,"데이터셋은 AI-Hub에서 제공하는 ",a.createElement(t.a,{href:"https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=&topMenu=&aihubDataSe=data&dataSetSn=97"},"문서요약 텍스트"),"를 사용할거예요.",a.createElement(t.br),"\n","위 데이터셋은 법률, 사설, 그리고 신문기사 총 세 가지 범주로 나뉘어 있는데, 우리의 관심 영역은 뉴스의 제목을 생성하는 것이기 때문에 뉴스 카테고리에 대한 데이터만 사용하는 것으로 하죠.\r\n데이터는 제목, 본문, 요약에 대한 정보 뿐 아니라 불용어 위치 정보, 미디어 명, 신뢰성과 같은 메타 데이터를 포함하고 있더라구요.\r\n일단 모델의 프로토타입을 만드는 것이 우선이니, 제목과 본문정보 정도만 쓰는 것으로 하고 후에 메타 데이터를 활용할 수 있는지 추가로 분석하는 것으로 하자구요."),"\n",a.createElement(t.p,null,"매번 학습을 시작할 때 마다 json 데이터를 읽고 여러 전처리 과정을 거치는 것이 생각보다 시간이 오래 걸려 처리된 데이터를 저장하고 학습 마다 불러오는 것으로 설계할게요."),"\n",a.createElement(t.pre,null,a.createElement(t.code,{className:"language-python"},"import json\r\nfrom threading import Thread\r\nfrom datasets import Dataset\r\n\r\ncreates_dataset = True\r\ndataset_file = '../data/dataset1.pt'\r\ntrain_file = '../data/train_original.json' # num of total data is about 240000\r\nvalid_file = '../data/valid_original.json' # num of total data is about 30000\r\nnum_threads = 8\r\n\r\n# read json & tokenize\r\ndef get_input_and_labels(documents, articles, abstractives):\r\n    for document in documents:\r\n        article = ''\r\n        for text in document['text']:\r\n            if len(text) > 0:\r\n                article += (text[0]['sentence'] + ' ')\r\n        articles.append(article)\r\n        \r\n        abstractive = document['abstractive']\r\n        if len(abstractive) > 0:\r\n            abstractive = abstractive[0]\r\n        abstractives.append(abstractive)\r\n        \r\ndef get_dataset_from_json(json_file, num_data=0):\r\n    with open(json_file, 'r') as f:\r\n        json_data = json.load(f)\r\n        documents = json_data['documents']\r\n        data_size = len(documents)\r\n        if num_data == 0 or num_data > data_size:\r\n            num_data = data_size\r\n        \r\n        data_per_threads = num_data//num_threads\r\n        t_results = []\r\n        threads = []\r\n        for i in range(num_threads-1):\r\n            t_result = [[], []]\r\n            t_results.append(t_result)\r\n            \r\n            thread = Thread(target=get_input_and_labels, args=(documents[i*data_per_threads:(i+1)*data_per_threads], t_result[0], t_result[1],))\r\n            thread.daemon = True\r\n            thread.start()\r\n            threads.append(thread)\r\n            \r\n        data_dict = {'article':[], 'abstractive':[]}\r\n        get_input_and_labels(documents[(num_threads-1)*data_per_threads:], data_dict['article'], data_dict['abstractive'])\r\n\r\n        for thread in threads:\r\n            thread.join()\r\n        \r\n        for t_result in t_results:\r\n            data_dict['article'].extend(t_result[0])\r\n            data_dict['abstractive'].extend(t_result[1])\r\n            \r\n        return Dataset.from_dict(data_dict)\r\n\r\nif creates_dataset:\r\n    train_dataset = get_dataset_from_json(train_file)\r\n    val_dataset = get_dataset_from_json(valid_file)\n")),"\n",a.createElement(t.p,null,"batch 작업을 위해 모든 input을 동일한 BART 최대 길이인 1024로 설정하였어요.\r\n기사 내용을 토큰화 하였을 때 1024보다 커지는 경우는 없더라구요.\r\n적절한 크기인 것 같습니다.\r\nlabel은 loss 계산 당시 동일한 input과 동일한 길이를 가져야 해서 똑같이 1024로 설정 해주겠습니다."),"\n",a.createElement(o.Z,null,a.createElement(t.p,null,"데이터를 토큰화까지 진행하고 저장하는 형식으로 만드려고 최대 길이 padding을 주었지만,\r\n하나의 batch로 묶인 데이터끼리만 padding을 주어 배치내 가장 큰 길이에 맞춰 padding하도록 해도 될듯")),"\n",a.createElement(t.pre,null,a.createElement(t.code,{className:"language-python"},"from torch.utils.data import DataLoader, TensorDataset\r\n\r\nbatch_size = 4\r\n\r\ndef preprocess(examples):\r\n    inputs = tokenizer(examples['article'], return_tensors='pt', max_length=1024, padding='max_length', truncation=True)\r\n    labels = tokenizer(examples['abstractive'], return_tensors='pt', max_length=1024, padding='max_length', truncation=True)\r\n    inputs['labels'] = labels['input_ids']\r\n    return inputs\r\n\r\ndef create_dataloader(dataset):\r\n    input_ids = dataset['input_ids']\r\n    attention_mask = dataset['attention_mask']\r\n    labels = dataset['labels']\r\n    tensor_dataset = TensorDataset(input_ids, attention_mask, labels)\r\n    return DataLoader(tensor_dataset, batch_size=batch_size)\r\n\r\nif creates_dataset:\r\n    dataloader = {\r\n        'train': create_dataloader(train_dataset.map(preprocess, batched=True).with_format(\"torch\")),\r\n        'val': create_dataloader(val_dataset.map(preprocess, batched=True).with_format(\"torch\"))\r\n    }\r\n    torch.save(dataloader, dataset_file)\r\nelse:\r\n    dataloader = torch.load(dataset_file)\n")),"\n",a.createElement(t.h1,{id:"train"},"Train"),"\n",a.createElement(t.p,null,"validation dataset 자체도 약 30,000개 데이터로 이루어져 있어 평가 시간이 오래 걸리지만 더 정확한 측정을 위해 sampling은 하지 않는 것으로 하겠습니다."),"\n",a.createElement(t.pre,null,a.createElement(t.code,{className:"language-python"},"# evaluate model\r\nfrom tqdm import tqdm\r\n\r\n@torch.no_grad()\r\ndef eval_model(model, val_dataloader):\r\n    device = next(model.parameters()).device\r\n    model.to(device)\r\n    model.eval()\r\n    total_loss = 0\r\n    \r\n    print('=== evaluate model')\r\n    for _, data in enumerate(tqdm(val_dataloader)):\r\n        data = [t.to(device) for t in data]\r\n        inputs = {\r\n            'input_ids': data[0],\r\n            'attention_mask': data[1],\r\n            'labels': data[2]\r\n        }\r\n        outputs =  model(**inputs)\r\n        loss = outputs.loss\r\n        total_loss += loss.item()\r\n    \r\n    total_loss /= len(val_dataloader)\r\n    print(f'total loss : {total_loss}')\r\n    \r\n    return total_loss\n")),"\n",a.createElement(t.p,null,"학습에는 epoch마다 선형적으로 learning rate를 감소시키는 scheduler를 사용할게요.",a.createElement(t.br),"\n","1 사이클 학습 하는데 하루가 걸려서 학습 중간에 checkpoint를 만들 필요가 있을 것 같아요.\r\n또한 ",a.createElement(t.code,null,"yolov8")," 모델에서 본 전략인데, 1 사이클마다 평가를 진행하고 가장 높은 점수를 받은 데이터를 best로 따로 저장해두는 전략을 사용합시다.",a.createElement(t.br),"\n","그리고 학습된 모델 weight를 직접 파일로 전달하지 않고 hub를 통해 접근 가능하도록 1 사이클이 끝날 때 마다 huggingface에 push하는 작업을 추가할게요."),"\n",a.createElement(t.pre,null,a.createElement(t.code,{className:"language-python"},"# train model\r\nimport os\r\nfrom torch.optim import AdamW, lr_scheduler\r\n\r\nclass Checkpoint():\r\n    def __init__(self, model, optimizer, scheduler) -> None:\r\n        self.model = model\r\n        self.optimizer = optimizer\r\n        self.scheduler = scheduler\r\n        self.epoch = 0\r\n        self.last_step = -1\r\n        self.best_loss = 1e20\r\n        \r\n    def set_root_dir(self, root_dir):\r\n        if root_dir is not None:\r\n            self.root_dir = root_dir\r\n            self.path = os.path.join(root_dir, 'checkpoint.pt')\r\n            \r\n            if not os.path.exists(root_dir):\r\n                os.makedirs(root_dir)\r\n                \r\n            if os.path.exists(self.path):\r\n                self.load(self.path)\r\n    \r\n    def load(self, save_path):\r\n        checkpoint = torch.load(save_path)\r\n        self.model.load_state_dict(checkpoint['model'])\r\n        self.optimizer.load_state_dict(checkpoint['optimizer'])\r\n        self.scheduler.load_state_dict(checkpoint['scheduler'])\r\n        self.epoch = checkpoint['epoch']\r\n        self.last_step = checkpoint['last_step']\r\n        self.best_loss = checkpoint['best_loss']\r\n    \r\n    def save(self):\r\n        if not self.path is None:\r\n            torch.save({\r\n                'model' : self.model.state_dict(),\r\n                'optimizer' : self.optimizer.state_dict(),\r\n                'scheduler' : self.scheduler.state_dict(),\r\n                'epoch' : self.epoch,\r\n                'last_step' : self.last_step,\r\n                'best_loss' : self.best_loss\r\n            }, self.path)\r\n        \r\n    def step(self):\r\n        self.optimizer.step()\r\n        self.last_step += 1\r\n    \r\n    def eval(self, val_dataloader):\r\n        if not self.root_dir is None:\r\n            loss = eval_model(self.model, val_dataloader)\r\n            if self.loss > loss:\r\n                self.loss = loss\r\n                torch.save(self.model.state_dict(), os.path.join(self.root_dir, 'best.pt'))\r\n    \r\n    def next(self):\r\n        self.scheduler.step()\r\n        self.epoch += 1\r\n        self.last_step = -1\r\n        self.save()\r\n        self.model.push_to_hub('yeti-s/kobart-base-v2-news-summarization', token=WRITE_TOKEN)\r\n        \r\n    def close(self):\r\n        if not self.path is None and os.path.exists(self.path):\r\n            os.remove(self.path)\r\n\r\n\r\ndef train_model(model, dataloader, checkpoint_dir=None, epochs=1, lr=2e-5, device=torch.device('cuda')):\r\n    model.to(device)\r\n    optimizer = AdamW(model.parameters(), lr=lr)\r\n    scheduler = lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda=lambda epoch:0.95**epoch)\r\n    checkpoint = Checkpoint(model, optimizer, scheduler)\r\n    checkpoint.set_root_dir(checkpoint_dir)\r\n\r\n    for epoch in range(checkpoint.epoch, epochs):\r\n        print(f'=== train model {epoch}/{epochs}')\r\n        model.train()\r\n        num_trained = 0\r\n        total_loss = 0\r\n        \r\n        for step, data in enumerate(tqdm(dataloader['train'])):\r\n            if step <= checkpoint.last_step:\r\n                continue\r\n            \r\n            data = [t.to(device) for t in data]\r\n            inputs = {\r\n                'input_ids': data[0],\r\n                'attention_mask': data[1],\r\n                'labels': data[2]\r\n            }\r\n\r\n            # get loss\r\n            optimizer.zero_grad()\r\n            outputs =  model(**inputs)\r\n            loss = outputs.loss\r\n            total_loss += loss.item()\r\n            \r\n            loss.backward()\r\n            checkpoint.step()\r\n            num_trained += 1\r\n            \r\n            # save checkpoint \r\n            if (step+1) % 1000 == 0:\r\n                checkpoint.save()\r\n                print(f'loss : {total_loss/num_trained}')\r\n        \r\n        checkpoint.eval(dataloader['val'])\r\n        checkpoint.next()\r\n        \r\n    # remove checkpoint\r\n    checkpoint.close()\n")))}var l=function(e){void 0===e&&(e={});const{wrapper:t}=Object.assign({},(0,n.ah)(),e.components);return t?a.createElement(t,e,a.createElement(s,e)):s(e)},i=r(4316),d=r(1840),c=r(2036),m=r(2654),p=r(4111),h=r(2726),_=r(4480),u=r(2818),f=r(9213),b=r(7213),v=r(9265),g=r(9601),k=r(3071),Z=r(6097),E=r(6782),w=r(4891),x=r(3387),j=r(917);const z=e=>{let{data:{mdx:t,file:r},children:o}=e;const s=(0,_.sJ)((0,u.cp)(u.eE,!1)),l=(0,_.sJ)((0,u.cp)(u.rf,!1)),i=(0,_.Zl)((0,u.cp)(u.Cy,t.tableOfContents.items));return(0,a.useEffect)((()=>{i(t.tableOfContents.items)}),[t]),(0,j.tZ)(d.Z,null,(0,j.tZ)(y,null,(0,j.tZ)(p.Z,null)),(0,j.tZ)(T,null,(0,j.tZ)(A,{className:"navigation",isNavOpened:l},(0,j.tZ)(N,null,(0,j.tZ)(c.Z,null))),(0,j.tZ)(q,{isNavOpened:l},(0,j.tZ)(D,{isWide:s},(0,j.tZ)(h.Z,{title:t.frontmatter.title,modifiedTime:r.modifiedTime}),(0,j.tZ)(n.Zo,{components:{p:b.Z,h1:v.H1,h2:v.H2,h3:v.H3,h4:v.H4,h5:v.H5,h6:v.H6,hr:g.Z,blockquote:k.Z,ul:E.Z,ol:Z.Z,pre:w.Z,code:x.Z}},o))),(0,j.tZ)(O,null,(0,j.tZ)(R,null,(0,j.tZ)(m.Z,null)))))},y=(0,i.Z)("div",{target:"e1ojob7j7"})({name:"11t2x7x",styles:"display:flex;height:var(--header-height);z-index:5;padding:0.6rem 2rem 0.6rem 0.6rem;position:fixed;width:100%;background:var(--background-color);border-bottom:1px solid var(--border-color)"}),T=(0,i.Z)("div",{target:"e1ojob7j6"})({name:"majwgz",styles:"position:relative;display:flex;min-height:calc(100vh - var(--header-height));overflow-x:hidden"}),A=(0,i.Z)("aside",{target:"e1ojob7j5"})("margin-left:",(e=>e.isNavOpened?"0":"calc(-1 * var(--sidebar-width))"),";flex:0 0 var(--sidebar-width);font-size:0.875rem;overflow-x:hidden;overflow-y:auto;padding-top:var(--body-padding-top);transition:margin 0.25s var(--ease-in-out-quad);@media (min-width: ",f.Z.IPAD_PRO,"px){margin-left:0;}"),N=(0,i.Z)("nav",{target:"e1ojob7j4"})({name:"1u006gd",styles:"position:fixed;width:var(--sidebar-width)"}),D=(0,i.Z)("main",{target:"e1ojob7j3"})("padding:1rem;width:100%;@media (min-width: ",f.Z.IPAD_AIR,"px){width:",(e=>e.isWide?"90%":"65%"),";}"),q=(0,i.Z)("main",{target:"e1ojob7j2"})("width:calc(100% - 2 * var(--sidebar-width));padding-top:var(--body-padding-top);flex-grow:1;min-width:20rem;display:flex;justify-content:center;opacity:",(e=>e.isNavOpened?.3:1),";@media (min-width: ",f.Z.IPAD_PRO,"px){opacity:1;}"),O=(0,i.Z)("aside",{target:"e1ojob7j1"})("font-size:0.75rem;font-weight:bold;overflow-x:hidden;overflow-y:auto;padding-top:var(--body-padding-top);width:0;transition:width 0.25s var(--ease-in-out-quad);@media (min-width: ",f.Z.HD,"px){width:var(--sidebar-width);}"),R=(0,i.Z)(N,{target:"e1ojob7j0"})({name:"b40oxt",styles:"padding:0 1rem 0 1rem"});function S(e){return a.createElement(z,e,a.createElement(l,e))}}}]);
//# sourceMappingURL=component---src-components-templates-main-template-tsx-content-file-path-contents-true-title-summarization-mdx-074dccef577b2b7e47c0.js.map